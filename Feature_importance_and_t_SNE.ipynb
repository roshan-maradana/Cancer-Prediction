{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Step 1: Load the Excel file\n",
        "# Replace 'Sheet1' with the actual sheet name if it's different\n",
        "df = pd.read_excel('Important_Features.xlsx', sheet_name='Sheet1')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "NJqbm_g3LC4e",
        "outputId": "fef2cb01-872c-46f6-99a9-948944e5693b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Important_Features.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2fef83153525>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Step 1: Load the Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Replace 'Sheet1' with the actual sheet name if it's different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Important_Features.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sheet1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Important_Features.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list for the target values\n",
        "target_values = [0]*50 + [1]*50\n",
        "\n",
        "# Add 'target' column to the DataFrame\n",
        "df['target'] = target_values\n",
        "df"
      ],
      "metadata": {
        "id": "T0wkRtYsLip4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kxpLh-uJnJy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 2: Prepare features and target\n",
        "# If your file has a 'target' column, this will work as is.\n",
        "# If the target column is named differently, adjust accordingly.\n",
        "X = df.drop(columns=['target'], errors='ignore')\n",
        "y = df['target']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,         # 20% data for testing # By default, train_test_split does shuffle the data before splitting.\n",
        "    random_state=42,       # for reproducibility\n",
        "    stratify=y             # important if target classes are imbalanced (guarantees that both train and test will have the same proportion of class 0 and class 1!)\n",
        ")\n",
        "\n",
        "# Step 3: Fit Random Forest\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Get feature importances\n",
        "importances = clf.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "importance_df = pd.DataFrame({'gene': feature_names, 'importance': importances})\n",
        "\n",
        "# Step 5: Sort and display top features\n",
        "top_features = importance_df.sort_values(by='importance', ascending=False).head(100)\n",
        "print(top_features)\n",
        "\n",
        "# Optional: Save the top features to a new Excel file\n",
        "top_features.to_excel('Top_Important_Features.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features=pd.read_excel('Top_Important_Features.xlsx')\n",
        "features"
      ],
      "metadata": {
        "id": "i1aylLNoQX1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genes_array=features['gene'].values"
      ],
      "metadata": {
        "id": "eMqq5fzKQ0h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.loc[:,df.columns.isin(genes_array)]\n",
        "\n",
        "new_df"
      ],
      "metadata": {
        "id": "n39Ob072Q8tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list for the target values\n",
        "target_values = [0]*50 + [1]*50\n",
        "\n",
        "# Add 'target' column to the DataFrame\n",
        "new_df['target'] = target_values\n",
        "new_df"
      ],
      "metadata": {
        "id": "Ri_1kLF9Utg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Convert all columns to string type before scaling\n",
        "new_df.columns = new_df.columns.astype(str)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(new_df.iloc[:, :-1])  # Exclude the target column\n",
        "\n",
        "# Run t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "tsne_results = tsne.fit_transform(data_scaled)\n",
        "\n",
        "# # Plot\n",
        "# plt.figure(figsize=(10,8))\n",
        "# sns.scatterplot(x=tsne_results[:,0], y=tsne_results[:,1], s=60)\n",
        "# plt.title('t-SNE visualization of 50non50tumor important dataset')\n",
        "# plt.xlabel('TSNE-1')\n",
        "# plt.ylabel('TSNE-2')\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming tsne_results (shape: [n_samples, 2]) and new_df (with 'target' column) are defined\n",
        "labels = new_df['target'].values  # or use the correct column name for your target\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "scatter = plt.scatter(\n",
        "    tsne_results[:, 0], tsne_results[:, 1],\n",
        "    c=labels, cmap='coolwarm', edgecolor='k', alpha=0.7\n",
        ")\n",
        "plt.title('t-SNE visualization of top genes target color coding')\n",
        "plt.xlabel('TSNE-1')\n",
        "plt.ylabel('TSNE-2')\n",
        "plt.colorbar(scatter, label='Target Label')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "48De1lFkSTvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = new_df.drop(columns=['target'])  # all columns except 'target'\n",
        "y = new_df['target']                 # target column\n",
        "\n",
        "# Split data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,         # 20% data for testing # By default, train_test_split does shuffle the data before splitting.\n",
        "    random_state=42,       # for reproducibility\n",
        "    stratify=y             # important if target classes are imbalanced (guarantees that both train and test will have the same proportion of class 0 and class 1!)\n",
        ")"
      ],
      "metadata": {
        "id": "1hhO1ly9XIje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "YQPxbb-qdGk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Train RandomForest on the PCA-transformed training data\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the PCA-transformed test data\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "Vet-bQe7W1KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Define classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define Stratified K-Fold\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 5 folds\n",
        "\n",
        "# Perform Cross-Validation\n",
        "scores = cross_val_score(rf, X, y, cv=kfold, scoring='accuracy')  # You can also use 'f1', 'roc_auc' etc.\n",
        "\n",
        "print(\"Cross-Validation Accuracy Scores:\", scores)\n",
        "print(\"Mean Accuracy:\", np.mean(scores))\n",
        "print(\"Standard Deviation:\", np.std(scores))\n",
        "\n",
        "# To get confusion matrix and classification report from cross-validation:\n",
        "# Need to do manual cross-validation (because cross_val_score only gives scores)\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_pred = cross_val_predict(rf, X, y, cv=kfold)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred))"
      ],
      "metadata": {
        "id": "XN4-XYpTdxJR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}